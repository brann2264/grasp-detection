{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733370641.704062  557511 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733370641.731734  559564 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733370641.752965  559568 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                       num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "finger_points = [4, 8, 12, 16, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_32(weights=torchvision.models.ViT_B_32_Weights.DEFAULT)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.heads = nn.Sequential(nn.Linear(768, 256), \n",
    "                            nn.GELU(),\n",
    "                            nn.BatchNorm1d(256),\n",
    "                            nn.Linear(256, 1))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"touch_vit_models/model_weights2.1_complete.pth\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_transforms = torchvision.models.ViT_B_32_Weights.IMAGENET1K_V1.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_index(img):\n",
    "    detection_result = detector.detect(img)\n",
    "    x = detection_result.hand_landmarks[0][8].x * 1920\n",
    "    y = detection_result.hand_landmarks[0][8].y * 1080\n",
    "    coords = np.array((x, y)).astype(int)\n",
    "    x_min, y_min = coords - 20 - 80\n",
    "    x_max, y_max = coords + 20 + 80\n",
    "    x_min, y_min = max(x_min,0), max(y_min,0)\n",
    "    x_max, y_max = min(x_max, 1920) , min(y_max, 1080)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, transforms=vit_transforms):\n",
    "    return transforms(torch.tensor(img.transpose((2, 0, 1))))[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 21:47:24.787 python[10865:545059] Warning: Window move completed without beginning\n"
     ]
    }
   ],
   "source": [
    "window_name = \"Touch prediction\"\n",
    "disp_x = 480 * 2\n",
    "disp_y = 384 * 2\n",
    "aspect_ratio = 480 / 384\n",
    "disp_frame = np.zeros((disp_y, disp_x, 3), dtype=np.uint8)\n",
    "cv2.imshow(window_name, disp_frame)\n",
    "\n",
    "#model.eval()\n",
    "\n",
    "while True:\n",
    "    ret, camera_frame = cap.read()\n",
    "    if camera_frame is None:\n",
    "        continue\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(camera_frame, cv2.COLOR_BGR2RGB)\n",
    "    img = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "    try:\n",
    "        x_min, x_max, y_min, y_max = locate_index(img)\n",
    "\n",
    "        input = process_img(camera_frame[y_min:y_max, x_min:x_max])\n",
    "        output = 1#model(input)\n",
    "        pred = torch.round(torch.sigmoid(output))\n",
    "\n",
    "        cv2.rectangle(camera_frame, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)\n",
    "\n",
    "        text = \"Touch\" if pred == 1 else \"No Contact\"\n",
    "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "        text_x = x_min\n",
    "        text_y = y_min - 10  # Position text above the bounding box\n",
    "        cv2.rectangle(\n",
    "            camera_frame,\n",
    "            (text_x, text_y - text_size[1] - 4),  # Text background\n",
    "            (text_x + text_size[0] + 4, text_y + 4),\n",
    "            (0, 0, 255),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            camera_frame,\n",
    "            text,\n",
    "            (text_x, text_y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(window_name, camera_frame)\n",
    "    keycode = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if keycode == ord('q'):\n",
    "        break    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(29):\n",
    "    camera_frame = cv2.imread(f\"/Users/brianchen/Research/grasp-detection/touch_dataset_new/no_contact/sample_0_{i}.jpeg\")\n",
    "    rgb_frame = cv2.cvtColor(camera_frame, cv2.COLOR_BGR2RGB)\n",
    "    img = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    out = detector.detect(img)\n",
    "    if len(out.hand_landmarks) > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HandLandmarkerResult(handedness=[[Category(index=1, score=0.981307864189148, display_name='Left', category_name='Left')], [Category(index=0, score=0.9776174426078796, display_name='Right', category_name='Right')]], hand_landmarks=[[NormalizedLandmark(x=0.3320728540420532, y=0.25143375992774963, z=7.14436438897792e-08, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.3079882860183716, y=0.4028165638446808, z=-0.03159911185503006, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.25680476427078247, y=0.5206488370895386, z=-0.046158984303474426, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.20127686858177185, y=0.5825384855270386, z=-0.06043625995516777, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.14470000565052032, y=0.6261320114135742, z=-0.07364130765199661, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.15390534698963165, y=0.4507398009300232, z=-0.00015102715406101197, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.0877712294459343, y=0.5128565430641174, z=-0.02312520146369934, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.04967401921749115, y=0.5600164532661438, z=-0.04952174052596092, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.016764216125011444, y=0.6068099737167358, z=-0.07107264548540115, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.13587813079357147, y=0.3784996569156647, z=-0.004075660835951567, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.06136123090982437, y=0.43821147084236145, z=-0.027673713862895966, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.020125016570091248, y=0.494512140750885, z=-0.05782369524240494, visibility=0.0, presence=0.0), NormalizedLandmark(x=-0.010249197483062744, y=0.5537711977958679, z=-0.08139179646968842, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.13610108196735382, y=0.3064386546611786, z=-0.014888834208250046, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.058411963284015656, y=0.34375080466270447, z=-0.042296964675188065, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.018870145082473755, y=0.3954031467437744, z=-0.06946001201868057, visibility=0.0, presence=0.0), NormalizedLandmark(x=-0.005008220672607422, y=0.45243728160858154, z=-0.08829280734062195, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.14877095818519592, y=0.22142884135246277, z=-0.028992900624871254, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.08292801678180695, y=0.24269726872444153, z=-0.057257279753685, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.049465663731098175, y=0.28863775730133057, z=-0.07765257358551025, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.02804495394229889, y=0.3468703031539917, z=-0.09192966669797897, visibility=0.0, presence=0.0)], [NormalizedLandmark(x=0.6149088144302368, y=0.12558577954769135, z=-3.544455395854129e-08, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6377978324890137, y=0.27582865953445435, z=-0.0438530370593071, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6082636117935181, y=0.4342665672302246, z=-0.07520876824855804, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5520572066307068, y=0.5329119563102722, z=-0.0921267494559288, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5014457106590271, y=0.6123013496398926, z=-0.10699240863323212, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5710026025772095, y=0.36612826585769653, z=-0.14392656087875366, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.4871079623699188, y=0.5226142406463623, z=-0.18489600718021393, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.44074320793151855, y=0.6343596577644348, z=-0.19181093573570251, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.4071407616138458, y=0.7158514261245728, z=-0.19205054640769958, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5243092179298401, y=0.2838617265224457, z=-0.13206321001052856, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.4198117256164551, y=0.4479700028896332, z=-0.1815073937177658, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.3721027970314026, y=0.5806486010551453, z=-0.18584918975830078, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.3479905426502228, y=0.6739631295204163, z=-0.18370385468006134, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.4847244918346405, y=0.23022881150245667, z=-0.11621417105197906, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.38602909445762634, y=0.3756503462791443, z=-0.15767435729503632, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.34489428997039795, y=0.5026465654373169, z=-0.16071036458015442, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.3269723057746887, y=0.5950837135314941, z=-0.15530413389205933, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.45669233798980713, y=0.19625458121299744, z=-0.10021453350782394, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.3813948929309845, y=0.3255690634250641, z=-0.12997202575206757, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.3548419177532196, y=0.4217453896999359, z=-0.13388052582740784, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.34547799825668335, y=0.49452441930770874, z=-0.13092561066150665, visibility=0.0, presence=0.0)]], hand_world_landmarks=[[Landmark(x=0.08902481198310852, y=-0.023877378553152084, z=-0.01682020165026188, visibility=0.0, presence=0.0), Landmark(x=0.06939012557268143, y=0.009108629077672958, z=-0.018141672015190125, visibility=0.0, presence=0.0), Landmark(x=0.04993195831775665, y=0.031125124543905258, z=-0.01724749431014061, visibility=0.0, presence=0.0), Landmark(x=0.024563845247030258, y=0.05175349861383438, z=-0.015775194391608238, visibility=0.0, presence=0.0), Landmark(x=-0.002813180908560753, y=0.06151704490184784, z=-0.012915548868477345, visibility=0.0, presence=0.0), Landmark(x=0.005225135013461113, y=0.025442492216825485, z=0.009701105765998363, visibility=0.0, presence=0.0), Landmark(x=-0.021479208022356033, y=0.033506300300359726, z=0.0029787865933030844, visibility=0.0, presence=0.0), Landmark(x=-0.038165610283613205, y=0.045545242726802826, z=-0.00823265127837658, visibility=0.0, presence=0.0), Landmark(x=-0.047573529183864594, y=0.06142018735408783, z=-0.03621556609869003, visibility=0.0, presence=0.0), Landmark(x=-0.002292814664542675, y=0.004439692012965679, z=0.008803480304777622, visibility=0.0, presence=0.0), Landmark(x=-0.03664254769682884, y=0.017897674813866615, z=-0.0010571584571152925, visibility=0.0, presence=0.0), Landmark(x=-0.051460810005664825, y=0.034610699862241745, z=-0.021939773112535477, visibility=0.0, presence=0.0), Landmark(x=-0.06595731526613235, y=0.05246926099061966, z=-0.041826777160167694, visibility=0.0, presence=0.0), Landmark(x=-0.0057829502038657665, y=-0.016835961490869522, z=-0.005786455702036619, visibility=0.0, presence=0.0), Landmark(x=-0.033230267465114594, y=-0.006163855083286762, z=-0.013408941216766834, visibility=0.0, presence=0.0), Landmark(x=-0.0510789230465889, y=0.009035030379891396, z=-0.03325134515762329, visibility=0.0, presence=0.0), Landmark(x=-0.061598651111125946, y=0.026873648166656494, z=-0.05547260493040085, visibility=0.0, presence=0.0), Landmark(x=0.005119464825838804, y=-0.030257821083068848, z=-0.020433207973837852, visibility=0.0, presence=0.0), Landmark(x=-0.01860831119120121, y=-0.028712619096040726, z=-0.02133854478597641, visibility=0.0, presence=0.0), Landmark(x=-0.0390014573931694, y=-0.01613755151629448, z=-0.03375770524144173, visibility=0.0, presence=0.0), Landmark(x=-0.04763242229819298, y=0.0015235114842653275, z=-0.05050589144229889, visibility=0.0, presence=0.0)], [Landmark(x=0.02850978635251522, y=-0.03278155252337456, z=0.07923060655593872, visibility=0.0, presence=0.0), Landmark(x=0.030968984588980675, y=-0.0045077321119606495, z=0.05169648677110672, visibility=0.0, presence=0.0), Landmark(x=0.01942240633070469, y=0.005119990557432175, z=0.03922327980399132, visibility=0.0, presence=0.0), Landmark(x=0.008234282955527306, y=0.017671186476945877, z=0.018018733710050583, visibility=0.0, presence=0.0), Landmark(x=-0.003800647333264351, y=0.0362643226981163, z=0.000587590504437685, visibility=0.0, presence=0.0), Landmark(x=0.007618937641382217, y=0.0051479823887348175, z=-0.0029642547015100718, visibility=0.0, presence=0.0), Landmark(x=-0.0018183602951467037, y=0.020389452576637268, z=-0.01038140244781971, visibility=0.0, presence=0.0), Landmark(x=-0.018299013376235962, y=0.038805875927209854, z=6.246339762583375e-05, visibility=0.0, presence=0.0), Landmark(x=-0.0288984477519989, y=0.05802023038268089, z=0.012380607426166534, visibility=0.0, presence=0.0), Landmark(x=0.0006723726401105523, y=0.00020345374650787562, z=-0.0028405103366822004, visibility=0.0, presence=0.0), Landmark(x=-0.020689120516180992, y=0.014899947680532932, z=-0.01419050246477127, visibility=0.0, presence=0.0), Landmark(x=-0.0337640605866909, y=0.04073485732078552, z=-0.008771916851401329, visibility=0.0, presence=0.0), Landmark(x=-0.048395052552223206, y=0.06161975860595703, z=0.019643522799015045, visibility=0.0, presence=0.0), Landmark(x=-0.007956966757774353, y=-0.001266975188627839, z=-4.337918653618544e-06, visibility=0.0, presence=0.0), Landmark(x=-0.02271052822470665, y=0.007075337693095207, z=-0.0067008365876972675, visibility=0.0, presence=0.0), Landmark(x=-0.04059277102351189, y=0.02553577348589897, z=0.0019113568123430014, visibility=0.0, presence=0.0), Landmark(x=-0.05231822282075882, y=0.04640444740653038, z=0.018145142123103142, visibility=0.0, presence=0.0), Landmark(x=-0.008737783879041672, y=-0.004085973836481571, z=0.016217732802033424, visibility=0.0, presence=0.0), Landmark(x=-0.02155444584786892, y=0.005692844744771719, z=0.014060226269066334, visibility=0.0, presence=0.0), Landmark(x=-0.04045895114541054, y=0.01843317784368992, z=0.018630091100931168, visibility=0.0, presence=0.0), Landmark(x=-0.04224982112646103, y=0.037053182721138, z=0.03170238807797432, visibility=0.0, presence=0.0)]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wilor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
